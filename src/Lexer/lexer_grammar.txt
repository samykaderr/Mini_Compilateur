Grammaire lexicale utilisée par Lexer

1. Vue d'ensemble
Le Lexer analyse une source JavaScript-like et produit des tokens. Les mots-clés sont reconnus (de façon insensible à la casse) ; les identifiants, nombres, chaînes, commentaires, opérateurs et ponctuation sont pris en charge. Les erreurs lexales courantes (chaîne non terminée, commentaire de bloc non fermé, symbole inconnu) sont signalées.

2. Notation
- <token> : nom du token / type (TokenType)
- "lexeme" : exemple de texte reconnu
- pattern : description informelle du motif

3. Liste des tokens et motifs
- EOF : fin de fichier
- IDENTIFIER : pattern = [A-Za-z_$][A-Za-z0-9_$]*  (ex: myVar, $elem, _private)
  - Les tokens qui correspondent à des mots-clés sont convertis en leur TokenType correspondant (voir section mots-clés). La comparaison est faite en minuscule (lexeme.toLowerCase()).

- NUMBER : nombres entiers ou décimaux simples
  - pattern approximatif : [0-9]+(\.[0-9]+)?
  - Exemples acceptés : 0 123 3.14 42.0
  - Remarque : un point suivi d'aucun chiffre après le point est considéré comme partie du lexeme NUMBER construit, mais peut être interprété différemment par le parser si nécessaire.

- STRING : chaînes entre guillemets simples ou doubles, supporte les échappements (\)
  - Délimiteurs : '...' ou "..."
  - Les séquences d'échappement simples sont acceptées (le lexer prend le caractère après un \ sans validation fine).
  - Si la chaîne n'est pas terminée avant la fin de fichier, le lexer signale une erreur et renvoie INVALID_TOKEN.

- SINGLE_LINE_COMMENT : // jusqu'à la fin de ligne (ex : // commentaire)
- MULTI_LINE_COMMENT : /* ... */ (ex : /* commentaire */)
  - Si le commentaire de bloc n'est pas fermé, le lexer signale une erreur et renvoie INVALID_TOKEN.

- INVALID_TOKEN : token utilisé pour les lexèmes invalides (chaînes non terminées, commentaires non fermés, symbole inconnu)

4. Mots-clés reconnus (lexeme comparé en minuscule)
let, var, const, function, return, if, else, while, do, for,
try, catch, finally, throw,
true, false, null, undefined,
console, log,
(plus deux personnalisés) samy, achouche

Ces mots-clés produisent les TokenType correspondants (ex : LET, VAR, TRY, CATCH, ...).

5. Opérateurs et ponctuation reconnus
- Arithmétiques / assignement/multi-caractères :
  +  => PLUS
  ++ => INCREMENT
  += => PLUS_ASSIGN
  -  => MINUS
  -- => DECREMENT
  -= => MINUS_ASSIGN
  *  => MULTIPLY
  *= => MULTIPLY_ASSIGN
  %  => MODULO
  /  => DIVIDE

- Comparaisons/logiques:
  ==  => EQUAL_EQUAL (note: code aussi gère '===' comme EQUAL_EQUAL avec lexeme "===")
  === => EQUAL_EQUAL
  !=  => NOT_EQUAL
  !== => NOT_EQUAL
  <   => LESS
  <=  => LESS_EQUAL
  >   => GREATER
  >=  => GREATER_EQUAL
  &&  => LOGICAL_AND
  ||  => LOGICAL_OR
  !   => LOGICAL_NOT

- Assignement simple:
  =  => ASSIGN

- Ponctuation:
  ; => SEMICOLON
  , => COMMA
  . => DOT
  ( => LPAREN
  ) => RPAREN
  { => LBRACE
  } => RBRACE
  [ => LBRACKET
  ] => RBRACKET

6. Règles additionnelles et comportement
- Ignoration de l'espace blanc : espaces, tabulations, retours chariot et sauts de ligne sont sautés entre les tokens par skipWhitespace().
- Suivi de position : le lexer maintien line et column pour chaque token (utile pour les messages d'erreur).
- Reconnaissance d'identifiants : accepte lettres, chiffres, '_' et '$'.
- Reconnaissance des mots-clés : le lexer fait keywords.get(lexeme.toLowerCase()) donc la table de mots-clés est traitée insensible à la casse. Le token garde le lexeme original (conservation de la casse dans le Token).
- Chaînes : le lexer inclut les guillemets ouvrant et fermant dans le lexeme retourné (par exemple "hello" comme lexeme complet). Les séquences d'escape sont conservées littéralement dans le lexeme retourné.

7. Erreurs lexicales gérées
- Symbole inconnu : tout caractère non pris en charge déclenche ErrorHandler.reportError et renvoie TokenType.INVALID_TOKEN.
- Chaîne non terminée : signale l'erreur, explique et renvoie INVALID_TOKEN avec le contenu collecté.
- Commentaire de bloc non fermé : signale l'erreur, explique et renvoie INVALID_TOKEN.

8. Exemples de lexèmes et tokens
Source : let x = 42; // commentaire
Tokens : LET, IDENTIFIER("x"), ASSIGN("="), NUMBER("42"), SEMICOLON(";"), SINGLE_LINE_COMMENT("// commentaire"), EOF

Source : if (a === b) { console.log("ok"); }
Tokens : IF, LPAREN, IDENTIFIER("a"), EQUAL_EQUAL("==="), IDENTIFIER("b"), RPAREN, LBRACE, CONSOLE, DOT, LOG, LPAREN, STRING("\"ok\""), RPAREN, SEMICOLON, RBRACE, EOF

9. Remarques pour le parser
- Quelques lexèmes ambigus (par exemple '.' après un nombre) peuvent être traités selon les besoins du Parser ; le Lexer tend à consommer le '.' comme DOT sauf si il a été déjà inclus dans le NUMBER lors de la détection du point suivi d'un chiffre.

10. Emplacement du fichier
Chemin créé : src/Lexer/lexer_grammar.txt

-- Fin du fichier --

